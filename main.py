import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import threading
import wikipediaapi
import requests
from urllib.parse import urlparse
from bs4 import BeautifulSoup
import time
import socket
import dns.resolver
import csv
import pandas as pd
import random
import os
import webbrowser
import json
from datetime import datetime
import re

try:
    import whois
except ImportError:
    whois = None


class WikiDomainChecker:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("WikiLink Domain Checker Enhanced")
        self.root.geometry("800x700")  # –£–≤–µ–ª–∏—á–∏–ª —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
        self.root.resizable(False, False)

        self.results = []
        self.all_checked_domains = []
        self.is_running = False
        self.stop_requested = False
        self.setup_ui()

    def save_csv(self):
        print("–í—ã–∑–≤–∞–Ω –º–µ—Ç–æ–¥ save_csv")
        if not self.all_checked_domains:
            messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        filepath = filedialog.asksaveasfilename(
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv")]
        )

        if filepath:
            try:
                with open(filepath, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow([
                        "–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ", "–°—Ç–∞—Ç—å—è", "–°—Å—ã–ª–∫–∞", "–î–æ–º–µ–Ω", "–°—Ç–∞—Ç—É—Å",
                        "–ê—Ä—Ö–∏–≤", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–Ω–∏–º–∫–æ–≤", "–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏",
                        "–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", "–ü—Ä–µ–≤—å—é —Ç–µ–∫—Å—Ç–∞"
                    ])
                    writer.writerows(self.all_checked_domains)
                messagebox.showinfo("–£—Å–ø–µ—Ö", f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self.all_checked_domains)} –∑–∞–ø–∏—Å–µ–π –≤: {filepath}")
            except Exception as e:
                messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å: {e}")

    def save_excel(self):
        print("–í—ã–∑–≤–∞–Ω –º–µ—Ç–æ–¥ save_excel")
        if not self.all_checked_domains:
            messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        filepath = filedialog.asksaveasfilename(
            defaultextension=".xlsx",
            filetypes=[("Excel files", "*.xlsx")]
        )

        if filepath:
            try:
                df = pd.DataFrame(self.all_checked_domains,
                                  columns=[
                                      "–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ", "–°—Ç–∞—Ç—å—è", "–°—Å—ã–ª–∫–∞", "–î–æ–º–µ–Ω", "–°—Ç–∞—Ç—É—Å",
                                      "–ê—Ä—Ö–∏–≤", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–Ω–∏–º–∫–æ–≤", "–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏",
                                      "–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã", "–ü—Ä–µ–≤—å—é —Ç–µ–∫—Å—Ç–∞"
                                  ])
                df.to_excel(filepath, index=False)
                messagebox.showinfo("–£—Å–ø–µ—Ö", f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self.all_checked_domains)} –∑–∞–ø–∏—Å–µ–π –≤: {filepath}")
            except Exception as e:
                messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å: {e}")

    def open_contact(self):
        print("–í—ã–∑–≤–∞–Ω –º–µ—Ç–æ–¥ open_contact")
        webbrowser.open("https://t.me/Userspoi")

    def setup_ui(self):
        print("–ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞...")

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_label = tk.Label(self.root, text="WikiLink Domain Checker Enhanced",
                               font=("Arial", 16, "bold"))
        title_label.pack(pady=10)

        # –ü–æ–ª–µ –≤–≤–æ–¥–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        tk.Label(self.root, text="–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):").pack(pady=5)
        self.keywords_entry = tk.Entry(self.root, width=60)
        self.keywords_entry.pack(pady=5)

        # –í—ã–±–æ—Ä —è–∑—ã–∫–∞
        lang_frame = tk.Frame(self.root)
        lang_frame.pack(pady=5)
        tk.Label(lang_frame, text="–Ø–∑—ã–∫ Wikipedia:").pack(side='left', padx=5)
        self.lang_var = tk.StringVar(value="ru")
        lang_options = [("–†—É—Å—Å–∫–∏–π", "ru"), ("English", "en"), ("Deutsch", "de"), ("Fran√ßais", "fr")]
        for text, value in lang_options:
            tk.Radiobutton(lang_frame, text=text, variable=self.lang_var,
                           value=value).pack(side='left', padx=5)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        options_frame = tk.Frame(self.root)
        options_frame.pack(pady=5)

        self.extract_content_var = tk.BooleanVar(value=True)
        tk.Checkbutton(options_frame, text="–ò–∑–≤–ª–µ–∫–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü",
                       variable=self.extract_content_var).pack(side='left', padx=5)

        self.check_snapshots_var = tk.BooleanVar(value=True)
        tk.Checkbutton(options_frame, text="–ü—Ä–æ–≤–µ—Ä—è—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–Ω–∏–º–∫–æ–≤",
                       variable=self.check_snapshots_var).pack(side='left', padx=5)

        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        control_frame = tk.Frame(self.root)
        control_frame.pack(pady=10)

        self.start_button = tk.Button(control_frame, text="–ù–∞—á–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É",
                                      command=self.start_check, bg="#4CAF50",
                                      fg="white", font=("Arial", 10, "bold"))
        self.start_button.pack(side='left', padx=5)

        self.stop_button = tk.Button(control_frame, text="–°—Ç–æ–ø",
                                     command=self.stop_check, bg="#f44336",
                                     fg="white", font=("Arial", 10, "bold"), state='disabled')
        self.stop_button.pack(side='left', padx=5)

        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
        self.progress = ttk.Progressbar(self.root, mode='indeterminate')
        self.progress.pack(pady=5, padx=20, fill='x')

        # –°—Ç–∞—Ç—É—Å
        self.status_label = tk.Label(self.root, text="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ", fg="green")
        self.status_label.pack(pady=5)

        # –õ–æ–≥
        tk.Label(self.root, text="–õ–æ–≥:").pack(pady=(10, 0))
        self.log_text = scrolledtext.ScrolledText(self.root, height=10, width=80)
        self.log_text.pack(pady=5, padx=20, fill='both', expand=True)

        # –ö–Ω–æ–ø–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_frame = tk.Frame(self.root, bg="lightgray", relief="raised", bd=2)
        save_frame.pack(pady=10, padx=10, fill='x')

        save_label = tk.Label(save_frame, text="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:",
                              font=("Arial", 10, "bold"), bg="lightgray")
        save_label.pack(pady=5)

        buttons_frame = tk.Frame(save_frame, bg="lightgray")
        buttons_frame.pack(pady=5)

        self.save_csv_button = tk.Button(buttons_frame, text="üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å CSV",
                                         command=self.save_csv,
                                         bg="#FF5722", fg="white",
                                         font=("Arial", 10, "bold"),
                                         width=15, height=2)
        self.save_csv_button.pack(side='left', padx=10)

        self.save_excel_button = tk.Button(buttons_frame, text="üìä –°–æ—Ö—Ä–∞–Ω–∏—Ç—å Excel",
                                           command=self.save_excel,
                                           bg="#4CAF50", fg="white",
                                           font=("Arial", 10, "bold"),
                                           width=15, height=2)
        self.save_excel_button.pack(side='left', padx=10)

        self.contact_button = tk.Button(buttons_frame, text="üìû –°–≤—è–∑—å",
                                        command=self.open_contact,
                                        bg="#2196F3", fg="white",
                                        font=("Arial", 10, "bold"),
                                        width=15, height=2)
        self.contact_button.pack(side='left', padx=10)

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.all_checked_domains = []
        self.log("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")

    def log(self, message):
        if hasattr(self, 'log_text'):
            timestamp = datetime.now().strftime("%H:%M:%S")
            self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
            self.log_text.see(tk.END)
            self.root.update()
        else:
            print(message)

    def start_check(self):
        if self.is_running:
            return

        keywords_text = self.keywords_entry.get().strip()
        if not keywords_text:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞")
            return

        keywords = [kw.strip() for kw in keywords_text.split(',')]
        language = self.lang_var.get()

        self.is_running = True
        self.stop_requested = False
        self.start_button.config(state='disabled')
        self.stop_button.config(state='normal')
        self.progress.start()
        self.status_label.config(text="–ü—Ä–æ–≤–µ—Ä–∫–∞...", fg="orange")
        self.log_text.delete(1.0, tk.END)
        self.results = []
        self.all_checked_domains = []

        thread = threading.Thread(target=self.check_domains, args=(keywords, language))
        thread.start()

    def stop_check(self):
        self.stop_requested = True
        self.log("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏...")

    def extract_page_content(self, url):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: –∑–∞–≥–æ–ª–æ–≤–æ–∫, –æ–ø–∏—Å–∞–Ω–∏–µ, —Ç–µ–∫—Å—Ç"""
        try:
            self.log(f"    –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            headers = {
                "User-Agent": "WikiLinkChecker/1.0 (https://example.com/contact)"
            }
            response = requests.get(url, headers=headers, timeout=10)

            if response.status_code != 200:
                return "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"

            soup = BeautifulSoup(response.text, 'html.parser')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω"
            if soup.title:
                title = soup.title.get_text().strip()
            elif soup.find('h1'):
                title = soup.find('h1').get_text().strip()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏ —Ç–µ–∫—Å—Ç
            description = ""

            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ meta description
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                description = meta_desc['content'].strip()

            # –ï—Å–ª–∏ –Ω–µ—Ç meta description, –±–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            if not description:
                paragraphs = soup.find_all('p')
                texts = []
                for p in paragraphs[:3]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
                    text = p.get_text().strip()
                    if text and len(text) > 20:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
                        texts.append(text)

                if texts:
                    description = ' '.join(texts)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
            if len(description) > 1000:
                description = description[:1000] + "..."

            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            description = re.sub(r'\s+', ' ', description).strip()
            title = re.sub(r'\s+', ' ', title).strip()

            if not description:
                description = "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

            self.log(f"    ‚úì –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title[:50]}...")
            self.log(f"    ‚úì –ü—Ä–µ–≤—å—é: {description[:100]}...")

            return title, description

        except Exception as e:
            self.log(f"    ‚ö† –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {e}")
            return "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞", "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"

    def get_archive_snapshots_count(self, domain):
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–Ω–∏–º–∫–æ–≤ –≤ Archive.org —á–µ—Ä–µ–∑ CDX API"""
        try:
            self.log(f"    –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–Ω–∏–º–∫–æ–≤ –¥–ª—è {domain}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º CDX API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–Ω–∏–º–∫–æ–≤
            url = f"https://web.archive.org/cdx/search/cdx?url={domain}&showNumPages=true"
            headers = {"User-Agent": "WikiLinkChecker/1.0"}

            response = requests.get(url, headers=headers, timeout=5)
            if response.status_code != 200:
                self.log(f"    CDX API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥ {response.status_code})")
                return 0

            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ—Ä–µ–∑ showNumPages
            text = response.text.strip()
            if text.isdigit():
                count = int(text)
                self.log(f"    ‚úì –ù–∞–π–¥–µ–Ω–æ {count} —Å–Ω–∏–º–∫–æ–≤")
                return count

            # –ï—Å–ª–∏ showNumPages –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Å—á–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫–∏
            lines = text.split('\n')
            count = len([line for line in lines if line.strip()])
            self.log(f"    ‚úì –ù–∞–π–¥–µ–Ω–æ {count} —Å–Ω–∏–º–∫–æ–≤")
            return count

        except Exception as e:
            self.log(f"    ‚ö† –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–Ω–∏–º–∫–æ–≤: {e}")
            return 0

    def check_domains(self, keywords, language):
        try:
            if self.stop_requested:
                return

            self.log(f"–ü–æ–∏—Å–∫ —Å—Ç—Ä–∞–Ω–∏—Ü Wikipedia ({language})...")
            pages = self.search_wikipedia(keywords, language)

            if not pages:
                self.log("–°—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                self.finish_check()
                return

            self.log(f"–ù–∞–π–¥–µ–Ω–æ {len(pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")

            for keyword, title, url in pages:
                if self.stop_requested:
                    break

                self.log(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {title}")
                external_links = self.fetch_external_links(url)

                if not external_links:
                    self.log("–í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    continue

                self.log(f"–ù–∞–π–¥–µ–Ω–æ {len(external_links)} –≤–Ω–µ—à–Ω–∏—Ö —Å—Å—ã–ª–æ–∫")

                for link in external_links:
                    if self.stop_requested:
                        break

                    domain = self.get_domain(link)
                    if not domain:
                        continue

                    self.log(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–º–µ–Ω: {domain}")

                    # –î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏
                    check_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–æ–º–µ–Ω–∞
                    is_available = self.check_domain_availability(domain)
                    self.log(f"  –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å: {'–¥–æ—Å—Ç—É–ø–µ–Ω' if is_available else '–∑–∞–Ω—è—Ç'}")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Archive.org
                    archive_info = self.check_archive_org(domain)
                    archive_text = archive_info if archive_info else "–Ω–µ –Ω–∞–π–¥–µ–Ω"

                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–Ω–∏–º–∫–æ–≤
                    snapshots_count = 0
                    if self.check_snapshots_var.get():
                        snapshots_count = self.get_archive_snapshots_count(domain)

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    page_title = "–ù–µ –∏–∑–≤–ª–µ–∫–∞–ª–æ—Å—å"
                    page_preview = "–ù–µ –∏–∑–≤–ª–µ–∫–∞–ª–æ—Å—å"

                    if self.extract_content_var.get():
                        page_title, page_preview = self.extract_page_content(link)

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    self.all_checked_domains.append((
                        keyword,
                        title,
                        link,
                        domain,
                        "–î–æ—Å—Ç—É–ø–µ–Ω" if is_available else "–ó–∞–Ω—è—Ç",
                        archive_text,
                        snapshots_count,
                        check_date,
                        page_title,
                        page_preview
                    ))

                    if is_available:
                        self.log(f"  ‚úì –î–æ–º–µ–Ω {domain} –¥–æ—Å—Ç—É–ø–µ–Ω")
                        self.results.append((keyword, title, link, domain, archive_text))
                    else:
                        self.log(f"  ‚úó –î–æ–º–µ–Ω {domain} –∑–∞–Ω—è—Ç")

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    time.sleep(random.uniform(1.0, 2.0))

        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞: {e}")

        self.finish_check()

    def finish_check(self):
        self.is_running = False
        self.progress.stop()
        self.start_button.config(state='normal')
        self.stop_button.config(state='disabled')

        if self.results:
            self.log(f"\n–ù–∞–π–¥–µ–Ω–æ {len(self.results)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤")
            self.log(f"–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –¥–æ–º–µ–Ω–æ–≤: {len(self.all_checked_domains)}")
            self.status_label.config(text="–ì–æ—Ç–æ–≤–æ", fg="green")
        else:
            if self.all_checked_domains:
                self.log(f"\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–æ–º–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                self.log(f"–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –¥–æ–º–µ–Ω–æ–≤: {len(self.all_checked_domains)}")
                self.status_label.config(text="–ì–æ—Ç–æ–≤–æ", fg="green")
            else:
                self.log("\n–î–æ–º–µ–Ω—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                self.status_label.config(text="–ì–æ—Ç–æ–≤–æ", fg="green")

    def search_wikipedia(self, keywords, language):
        user_agent = "WikiLinkChecker/1.0"
        wiki_wiki = wikipediaapi.Wikipedia(
            language=language,
            extract_format=wikipediaapi.ExtractFormat.WIKI,
            user_agent=user_agent
        )

        results = []
        for keyword in keywords:
            if self.stop_requested:
                break

            try:
                page = wiki_wiki.page(keyword)
                if page.exists():
                    results.append((keyword, page.title, page.fullurl))
                    continue

                search_results = wiki_wiki.search(keyword, results=5)
                for search_result in search_results:
                    if self.stop_requested:
                        break
                    page = wiki_wiki.page(search_result)
                    if page.exists():
                        results.append((keyword, page.title, page.fullurl))

            except Exception as e:
                self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{keyword}': {e}")
                continue

        return results

    def fetch_external_links(self, page_url):
        try:
            headers = {"User-Agent": "WikiLinkChecker/1.0"}
            response = requests.get(page_url, headers=headers, timeout=10)
            if response.status_code != 200:
                return set()

            soup = BeautifulSoup(response.text, 'html.parser')
            external_links = set()

            for a_tag in soup.find_all('a', href=True):
                href = a_tag['href']
                if href.startswith(('http://', 'https://')):
                    if 'wikipedia.org' not in href and 'wikimedia.org' not in href:
                        external_links.add(href)

            return external_links
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å—Å—ã–ª–æ–∫: {e}")
            return set()

    def get_domain(self, url):
        try:
            parsed = urlparse(url)
            domain = parsed.netloc
            if domain.startswith('www.'):
                domain = domain[4:]

            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –¥–æ–º–µ–Ω—ã
            if not domain or ':' in domain or 'archive.org' in domain or 'wayback' in domain:
                return None

            return domain
        except:
            return None

    def check_archive_org(self, domain):
        try:
            self.log(f"    –ü—Ä–æ–≤–µ—Ä—è–µ–º Archive.org –¥–ª—è {domain}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º CDX API –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è —Å–Ω–∏–º–∫–æ–≤
            url = f"https://web.archive.org/cdx/search/cdx?url={domain}&limit=1"
            headers = {"User-Agent": "WikiLinkChecker/1.0"}

            response = requests.get(url, headers=headers, timeout=6)
            if response.status_code != 200:
                self.log(f"    Archive.org –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥ {response.status_code})")
                return "Archive.org –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

            text = response.text.strip()
            if not text:
                self.log(f"    ‚úó –°–Ω–∏–º–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return "—Å–Ω–∏–º–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

            # –ü–∞—Ä—Å–∏–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É CDX –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞—Ç—ã
            lines = text.split('\n')
            if lines and lines[0].strip():
                parts = lines[0].split(' ')
                if len(parts) >= 2:
                    timestamp = parts[1]
                    if len(timestamp) >= 8:
                        date_str = f"{timestamp[:4]}-{timestamp[4:6]}-{timestamp[6:8]}"
                        self.log(f"    ‚úì –ù–∞–π–¥–µ–Ω —Å–Ω–∏–º–æ–∫: {date_str}")
                        return f"–ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∏–º–æ–∫ {date_str}"

            self.log(f"    ‚úì –ù–∞–π–¥–µ–Ω—ã —Å–Ω–∏–º–∫–∏")
            return "–Ω–∞–π–¥–µ–Ω—ã —Å–Ω–∏–º–∫–∏"

        except Exception as e:
            self.log(f"    ‚ö† –û—à–∏–±–∫–∞ Archive.org –¥–ª—è {domain}: {e}")
            return "–æ—à–∏–±–∫–∞ Archive.org"

    def check_domain_availability(self, domain):
        try:
            if whois:
                try:
                    w = whois.whois(domain)
                    if w.domain_name:
                        return False
                except:
                    pass

            try:
                answers = dns.resolver.resolve(domain, 'A')
                return False
            except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer):
                return True
            except:
                return False

        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–º–µ–Ω–∞ {domain}: {e}")
            return False

    def run(self):
        self.root.mainloop()


if __name__ == "__main__":
    app = WikiDomainChecker()
    app.run()
